# üèóÔ∏è Documentation Technique - NIBRASSE (ŸÜÿ®ŸÄŸÄÿ±ÿßÿ≥)

Ce document d√©taille l'architecture avanc√©e, la stack technique et les algorithmes qui font la pr√©cision de **NIBRASSE**.

---

## 1. Vue d'Ensemble & Technologies Cl√©s

**NIBRASSE** est une application RAG (Retrieval-Augmented Generation) de haute pr√©cision. Sa force r√©side dans son pipeline de recherche hybride et ses techniques de re-classement (Reranking).

### Stack Technique
*   **Frontend** : HTML5, CSS3 (Vanilla + Glassmorphism), JavaScript (Vanilla ES6+).
*   **Backend** : Python 3.10+, FastAPI, Uvicorn.
*   **Base de Donn√©es** : Supabase (PostgreSQL) pour les m√©tadonn√©es.
*   **Vector Store** : ChromaDB (Local/Persistent) pour les embeddings.
*   **AI / LLM** : Google Gemini Pro (G√©n√©ration) & Gemini Embedding (Vectorisation).

### üöÄ Technologies de Pr√©cision (Le C≈ìur du Syst√®me)
Ce sont les √©l√©ments qui garantissent la pertinence des r√©ponses :

1.  **Recherche Hybride (Hybrid Search)** :
    *   Combine la **recherche s√©mantique** (Vecteurs) pour comprendre le sens.
    *   Et la **recherche par mots-cl√©s** (BM25) pour trouver les termes exacts.
    *   C'est crucial pour les documents techniques ou juridiques o√π chaque mot compte.

2.  **Reciprocal Rank Fusion (RRF)** :
    *   Algorithme qui fusionne les r√©sultats de la recherche vectorielle et de BM25.
    *   Il normalise les scores pour donner un classement unifi√© et √©quitable.

3.  **Embeddings Haute Dimension** :
    *   Utilisation du mod√®le `models/embedding-001` de Google.
    *   Dimension des vecteurs : **768**.
    *   Permet une repr√©sentation riche et nuanc√©e du texte.

4.  **Re-ranking (R√©√©valuation)** :
    *   Les meilleurs r√©sultats de la recherche hybride sont relus par le LLM (Gemini).
    *   Le mod√®le attribue un score de pertinence (0-10) √† chaque passage.
    *   Seuls les passages les plus pertinents sont envoy√©s au g√©n√©rateur de r√©ponse.

5.  **Expansion de Requ√™te (Query Expansion)** :
    *   Le syst√®me g√©n√®re des variantes de la question utilisateur pour couvrir plus d'angles de recherche.

---

## 2. Architecture du Projet

### üìÇ `backend/`
Contient toute la logique serveur et RAG.
*   `app/services/rag.py` : Pipeline RAG complet (Expansion -> Hybride (Chroma+BM25) -> RRF -> Reranking -> G√©n√©ration).
*   `app/services/ingestion.py` : Traitement des fichiers. **Conversion automatique** des PDF/DOCX en texte brut (.txt) avant traitement.
*   `app/services/bm25_service.py` : Moteur de recherche lexical (Mots-cl√©s).

### üìÇ `frontend_new/`
Interface utilisateur moderne.
*   `app.js` : Gestion de l'√©tat local (LocalStorage) pour la persistance des conversations.

---

## 3. Flux de Donn√©es (Workflows)

### A. Ingestion de Documents (`/api/upload`)
1.  **Conversion** : Les fichiers (PDF, DOCX, TXT) sont convertis en texte brut.
2.  **Chunking** : D√©coupage intelligent du texte (taille 512, chevauchement 150) optimis√© pour l'arabe et le fran√ßais.
3.  **Embedding** : Vectorisation des chunks (768 dimensions).
4.  **Indexation** :
    *   Vecteurs -> ChromaDB.
    *   Mots-cl√©s -> Index BM25 (M√©moire).
    *   M√©tadonn√©es -> Supabase.

### B. Interrogation RAG (`/api/query`)
1.  **Expansion** : La requ√™te est enrichie.
2.  **Recherche Parall√®le** :
    *   ChromaDB (S√©mantique).
    *   BM25 (Lexical).
3.  **Fusion (RRF)** : Combinaison des r√©sultats.
4.  **Reranking** : Le LLM filtre les r√©sultats non pertinents.
5.  **G√©n√©ration** : Gemini Pro r√©dige la r√©ponse finale avec citations.

---

## 4. Configuration

Le fichier `.env` doit contenir les cl√©s API pour Gemini et Supabase.

---

## 5. Pistes d'Am√©lioration

1.  **Persistance Serveur** : Synchronisation DB des conversations.
2.  **Streaming** : Affichage progressif de la r√©ponse.
3.  **Optimisation BM25** : Sauvegarde de l'index sur disque pour les gros volumes.
