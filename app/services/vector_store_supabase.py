"""
Vector Store implementation using Supabase pgvector
ÙŠØ³ØªØ¨Ø¯Ù„ ChromaDB Ø¨Ù€ Supabase pgvector Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Vercel
"""
import json
import os
import psycopg2
from psycopg2.extras import RealDictCursor
from app.services.database import get_supabase
from typing import List, Dict, Any

def add_documents_to_supabase(
    ids: List[str],
    documents: List[str],
    metadatas: List[Dict[str, Any]],
    embeddings: List[List[float]]
):
    """
    Ø¥Ø¶Ø§ÙØ© documents Ù…Ø¹ embeddings Ø¥Ù„Ù‰ Supabase
    
    Args:
        ids: Ù‚Ø§Ø¦Ù…Ø© IDs (embedding_id)
        documents: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†ØµÙˆØµ
        metadatas: Ù‚Ø§Ø¦Ù…Ø© metadata (ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ document_id, chunk_index, filename)
        embeddings: Ù‚Ø§Ø¦Ù…Ø© vectors (768 dimension)
    """
    supabase = get_supabase()
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¥Ø¯Ø±Ø§Ø¬
    chunks_data = []
    for i in range(len(ids)):
        # ØªØ­ÙˆÙŠÙ„ embedding Ù„Ù€ list Ø¥Ø°Ø§ ÙƒØ§Ù† numpy array
        embedding = embeddings[i]
        if hasattr(embedding, 'tolist'):
            embedding = embedding.tolist()
        
        # âœ… Ù„Ù„ØªØ®Ø²ÙŠÙ†: Ù†Ø±Ø³Ù„ list Ù…Ø¨Ø§Ø´Ø±Ø© (Supabase ÙŠØ­ÙˆÙ„Ù‡Ø§ Ù„Ù€ vector ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹)
        # âš ï¸ Ù„Ù„Ø¨Ø­Ø«: Ù†Ø±Ø³Ù„ text (RPC ÙŠØ­ÙˆÙ„Ù‡Ø§ ØµØ±Ø§Ø­Ø©Ù‹ Ø¨Ù€ ::vector)
        
        chunk_data = {
            "document_id": metadatas[i].get("document_id"),
            "chunk_index": metadatas[i].get("chunk_index"),
            "content": documents[i],
            "embedding_id": ids[i],
            "embedding": embedding  # âœ… list Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„ØªØ®Ø²ÙŠÙ†
        }
        chunks_data.append(chunk_data)
    
    # Ø·Ø¨Ø§Ø¹Ø© debug info Ù„Ø£ÙˆÙ„ chunk
    if len(chunks_data) > 0:
        test_emb = chunks_data[0]['embedding']
        print(f"ğŸ“Š Debug - Embedding info:")
        print(f"   - Type: {type(test_emb)}")
        print(f"   - Length: {len(test_emb)}")
        if len(test_emb) > 0:
            print(f"   - First element type: {type(test_emb[0])}")
    
    # Ø¥Ø¯Ø±Ø§Ø¬ ÙÙŠ Supabase (batch) - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
    response = supabase.table("chunks_v2").insert(chunks_data).execute()  # âœ… v2
    
    print(f"âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© {len(chunks_data)} chunks Ø¥Ù„Ù‰ Supabase pgvector (v2)")
    
    return response.data


def query_supabase_vectors(
    query_embedding: List[float],
    n_results: int = 20,
    filter_document_id: int = None
) -> Dict[str, Any]:
    """
    Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ÙÙŠÙƒØªÙˆØ±ÙŠ ÙÙŠ Supabase Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PostgreSQL Ù…Ø¨Ø§Ø´Ø±Ø©
    
    Args:
        query_embedding: vector Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… (768 dimension)
        n_results: Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        filter_document_id: ØªØµÙÙŠØ© Ø­Ø³Ø¨ document_id (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
    
    Returns:
        Ù†ØªØ§Ø¦Ø¬ Ø¨Ù†ÙØ³ Ø´ÙƒÙ„ ChromaDB
    """
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† query_embedding Ù‡Ùˆ list
    if hasattr(query_embedding, 'tolist'):
        query_embedding = query_embedding.tolist()
    
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Database URL Ù…Ù† .env
    db_url = os.getenv('SUPABASE_DB_URL')
    
    if not db_url:
        print("âŒ Error: SUPABASE_DB_URL not found in .env")
        return {"ids": [[]], "distances": [[]], "metadatas": [[]], "documents": [[]]}
    
    try:
        # Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ PostgreSQL Ù…Ø¨Ø§Ø´Ø±Ø©
        conn = psycopg2.connect(db_url)
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        # ØªØ­ÙˆÙŠÙ„ embedding Ù„Ù€ PostgreSQL array format
        embedding_str = '[' + ','.join([str(x) for x in query_embedding]) + ']'
        
        print(f"ğŸ” Debug:")
        print(f"   - embedding_str[:100]: {embedding_str[:100]}")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† database Ùˆ schema
        cursor.execute("SELECT current_database(), current_schema()")
        db_info = cursor.fetchone()
        print(f"   - Current DB: {db_info}")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        cursor.execute("SELECT COUNT(*) FROM chunks_v2")
        count = cursor.fetchone()
        print(f"   - Total rows in chunks_v2: {count}")
        
        # SQL query Ù…Ø¹ embedding Ù…Ø¨Ø§Ø´Ø±Ø©
        query = f"""
            SELECT
                id,
                document_id,
                chunk_index,
                content,
                embedding_id,
                1 - (embedding <=> '{embedding_str}'::vector) as similarity
            FROM chunks_v2
            ORDER BY embedding <=> '{embedding_str}'::vector
            LIMIT {n_results}
        """
        
        print(f"   - Query first 200 chars: {query[:200]}")
        
        cursor.execute(query)
        results = cursor.fetchall()
        
        print(f"   - Raw results count: {len(results)}")
        if results:
            print(f"   - First result: {results[0]}")
        
        cursor.close()
        conn.close()
        
        print(f"âœ… PostgreSQL direct: found {len(results)} results")
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù†ÙØ³ Ø´ÙƒÙ„ ChromaDB
        documents = []
        ids = []
        metadatas = []
        distances = []
        
        for row in results:
            documents.append(row['content'])
            ids.append(str(row['id']))
            metadatas.append({
                "document_id": row['document_id'],
                "chunk_index": row['chunk_index'],
                "embedding_id": row['embedding_id']
            })
            distances.append(row['similarity'])
        
        return {
            "ids": [ids],
            "distances": [distances],
            "metadatas": [metadatas],
            "documents": [documents]
        }
        
    except Exception as e:
        print(f"âŒ PostgreSQL Error: {e}")
        import traceback
        traceback.print_exc()
        return {"ids": [[]], "distances": [[]], "metadatas": [[]], "documents": [[]]}


def get_collection_count() -> int:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ù€ chunks ÙÙŠ Supabase v2
    """
    supabase = get_supabase()
    result = supabase.rpc('check_migration_status_v2').execute()  # âœ… v2
    
    if result.data and len(result.data) > 0:
        return result.data[0]['total_rows']
    
    return 0


def delete_collection():
    """
    Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ chunks Ù…Ù† v2 (Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙÙ‚Ø·)
    âš ï¸ Ø§Ø³ØªØ®Ø¯Ù… Ø¨Ø­Ø°Ø±!
    """
    supabase = get_supabase()
    supabase.table("chunks_v2").delete().neq('id', 0).execute()  # âœ… v2
    print("âš ï¸ ØªÙ… Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù€ chunks Ù…Ù† Supabase v2")
